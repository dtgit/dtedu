# Gettext Message File for ECQuiz.
# -*- coding: utf-8 -*-
msgid ""
msgstr ""
"Project-Id-Version: ECQuiz\n"
"POT-Creation-Date: 2004-11-25 10:29 +0100\n"
"PO-Revision-Date: 2007-06-27 19:32\n"
"Last-Translator: Michael Piotrowski <mxp@iws.cs.uni-magdeburg.de>\n"
"Language-Team: eduComponents <educomponents@uni-magdeburg.de>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"Language-Code: fr\n"
"Language-Name: Français\n"
"Preferred-Encodings: utf-8 latin1\n"
"Domain: ECQuiz\n"
"X-Is-Fallback-For: fr-be fr-ca fr-lu fr-mc fr-ch fr-fr\n"

#. <input class="context"
#. tabindex="#"
#. type="submit"
#. name="export"
#. value="Export"
#. tal:attributes="tabindex tabindex/next;"
#. i18n:attributes="value"
#. />
msgid "Export"
msgstr "Exporter"

#. <input class="context"
#. tabindex="#"
#. type="submit"
#. name="importTest:method"
#. value="Import"
#. tal:attributes="tabindex tabindex/next;"
#. i18n:attributes="value"
#. />
#: skins\llsMultipleChoice\test_import_export.pt
msgid "Import"
msgstr "Importer"

#. Default: N/A
#: ./skins/llsMultipleChoice/exportResults.py, 85
msgid "N/A"
msgstr "---"

#. Default: Next
#: skins/llsMultipleChoice/test_view.pt
msgid "Next"
msgstr "Suivant"

#. Default: Previous
#: skins/llsMultipleChoice/test_view.pt
msgid "Previous"
msgstr "Précédent"

#. <input class="context" type="submit"
#. name="sendButton" value="Repeat"
#. i18n:attributes="value"/>
msgid "Repeat"
msgstr "Repasser"

#. Default: Submit Test
#: skins/llsMultipleChoice/test_view.pt
#, fuzzy
msgid "Submit Test"
msgstr "Soumettre le test"

#. Default: Upload
#. <input class="context"
#. tabIndex=""
#. type="submit"
#. value="Upload"
#. tal:attributes="tabIndex tabIndex/next;"
#. i18n:attributes="value"
#. />
#: skins/llsMultipleChoice/test_import_export.pt
msgid "Upload"
msgstr "Charger"

#. Default: Do you really want to submit this test?
#: skins/llsMultipleChoice/test_view.pt
msgid "alert_really_submit"
msgstr "Vous êtes sûrs que vous voulez soumettre ce test ?"

# Already defined in plone-de.po
# msgid "Delete"
# msgstr "Löschen"
#. <input class="context"
#. tabindex="#"
#. type="submit"
#. name="delete"
#. value="Delete"
#. tal:attributes="tabindex tabindex/next;"
#. i18n:attributes="value"
#. />
#. <h2 i18n:translate="all_tests">All Tests</h2>
msgid "all_tests"
msgstr "Touts les tests"

#. <p tal:condition="not: nonSubmitters" i18n:translate="all_tests_submitted">
#. All tests have been submitted.
#. </p>
msgid "all_tests_submitted"
msgstr "Alle Tests wurden eingereicht."

#. BooleanField('allowMultipleSelection',
#. # If 'allowMultipleSelection' is True, this is a multiple answer
#. # question, i.e. one where more than one answer can be true. Otherwise
#. # it is a multiple choice question, i.e. exactly only one answer is
#. # correct.
#. #   The question_view template is designed to support this. When
#. # 'allowMultipleSelection' is True, radio buttons will be generated.
#. # If not, check boxes will be shown.
#. #   See also 'description' property of the widget.
#. accessor='isAllowMultipleSelection',
#. default=1,
#. searchable=False,
#. widget=BooleanWidget(
#. label='Allow Multiple Selection',
#. label_msgid='allow_multiple_selection_label',
#. description='If the selection of multiple answers should be possible, mark this checkbox.',
#. description_msgid='allow_multiple_selection_tool_tip',
#. i18n_domain='llsMultipleChoice'),
#. ),
#. label_#msgid='allow_multiple_selection_label',
#. description_#msgid='allow_multiple_selection_tool_tip',
msgid "allow_multiple_selection_label"
msgstr "Permettre un choix multiple"

msgid "allow_multiple_selection_tool_tip"
msgstr "Selectionnez ce bouton si vous voulez permettre un choix multiple de réponses.\n"

#. BooleanField('allowRepetition',
#. required=False,
#. default=0,
#. accessor='isAllowRepetition',
#. widget=BooleanWidget(
#. label='Allow Repetition',
#. label_msgid='allow_repetition_label',
#. description='If you want to allow repeated submission of the test'\
#. + 'check this box.',
#. description_msgid='allow_repetition_tool_tip',
#. i18n_domain='llsMultipleChoice'),
#. ),
#. label_#msgid='allow_repetition_label',
#. description='If you want to allow repeated submission of the test'#.                + 'check this box.',
#. description_#msgid='allow_repetition_tool_tip',
msgid "allow_repetition_label"
msgstr "Permettre de repasser le test"

msgid "allow_repetition_tool_tip"
msgstr "Choisissez cette option si les candidats peuvent repasser le test"

#. errors.write('\n' + context.translate(
#. msgid   = 'ambiguous_reference',
#. domain  = I18N_DOMAIN,
#. default = 'There is more than one resource with '
#. 'the identifier "%s". Only the first one will '
#. 'be imported.'
#. ) % context.str(identifierref))
#. #msgid   = 'ambiguous_reference',
#: qti.py
msgid "ambiguous_reference"
msgstr "Il y a plusieurs ressources avec l'identification « %s ». Seulement la première d'elles sera importée."

#. TextField('comment',
#. searchable=True,
#. required=False,
#. widget=TextAreaWidget(
#. label='Comment',
#. label_msgid='answer_comment_label',
#. description='A comment on the answer. If the test is set to "instant feedback", ' \
#. + 'the candidate will see this text in case his/her answer was wrong.',
#. description_msgid='answer_comment_tool_tip',
#. i18n_domain='llsMultipleChoice'),
#. label_#msgid='answer_comment_label',
#. description='A comment on the answer. If the test is set to "instant feedback", ' #.            + 'the candidate will see this text in case his/her answer was wrong.',
#. description_#msgid='answer_comment_tool_tip',
msgid "answer_comment_label"
msgstr "Commentaire"

msgid "answer_comment_tool_tip"
msgstr "Un commentaire pour la réponse. Si le présentation immédiate des résultats est active, ce texte sera affiché au candidat en cas d'une réponse incorrecte."

#. widget=TextAreaWidget(
#. label='Answer',
#. label_msgid='answer_label',
#. description='The answer text. This is what the candidate will see.',
#. description_msgid='answer_tool_tip',
#. i18n_domain='plone'),
#. label_#msgid='answer_label',
#. description_#msgid='answer_tool_tip',
msgid "answer_label"
msgstr "Réponse"

#. Default: A Unicode checkmark character
#. <tal:block condition="correct" i18n:translate="answer_mark_correct">
#. <span style="color:green;">&#10003;</span>
#. </tal:block>
#: skins/llsMultipleChoice/multiplechoicequestion_view.pt
msgid "answer_mark_correct"
msgstr ""

#. Default: A Unicode right arrow character
#. <tal:block condition="python:correct and not checked"
#. i18n:translate="answer_mark_correct_not_selected">
#. <span style="color:gray;">&#x279C;</span>
#. </tal:block>
#: skins/llsMultipleChoice/multiplechoicequestion_view.pt
msgid "answer_mark_correct_not_selected"
msgstr ""

#. Default: A Unicode ballot X character
#. <tal:block condition="not: correct" i18n:translate="answer_mark_wrong">
#. <span style="color:red;">&#10007;</span>
#. </tal:block>
#: skins/llsMultipleChoice/multiplechoicequestion_view.pt
msgid "answer_mark_wrong"
msgstr ""

#. Default: Answer Template
#: ./QuestionTypes/ExtendedTextQuestion.py, 54
msgid "answer_template_label"
msgstr "Modèle pour la réponse"

#. Default: You can provide a template for the candidate's answer.
#: ./QuestionTypes/ExtendedTextQuestion.py, 57
msgid "answer_template_tool_tip"
msgstr "Vous pouvez spécifier un modèle ou un cadre pour la réponse de candidats."

msgid "answer_tool_tip"
msgstr "Le texte de la réponse qui est présenté au candidat."

#. msg = context.translate(\
#. msgid   = 'answers_saved',\
#. domain  = I18N_DOMAIN,\
#. default = 'Your answers have been saved.')
#. msg = context.translate(#.     #msgid   = 'answers_saved',#.     domain  = I18N_DOMAIN,#.     default = 'Your answers have been saved.')
#: Script (Python) "submitTest"
msgid "answers_saved"
msgstr "Vos réponses ont étés enregistrées."

#. <a tal:attributes="href string:test_results#overview_${submitterId}"
#. i18n:translate="back_to_overview">Back to the overview</a>
msgid "back_to_overview"
msgstr "Retourner au résumé"

#. <th i18n:translate="candidate">Candidate</th>
msgid "candidate"
msgstr "Candidat"

#. widget=BooleanWidget(
#. label='Correct',
#. label_msgid='correct_label',
#. description='The checkbox should be marked if this is a correct answer.',
#. description_msgid='correct_tool_tip',
#. i18n_domain='plone'),
#. label_#msgid='correct_label',
#. description_#msgid='correct_tool_tip',
msgid "correct_label"
msgstr "Correct"

msgid "correct_tool_tip"
msgstr "Choisissez ce bouton pour une réponse correcte.\n"

#. msg = context.translate(
#. msgid   = 'deleteResults_no_permission',
#. domain  = 'llsMultipleChoice',
#. default = 'You do not have permission to delete results.')
#. #msgid   = 'deleteResults_no_permission',
msgid "deleteResults_no_permission"
msgstr "Vou n'avez pas la permission pour supprimer des résultats."

#. <span i18n:translate="delete_results" tal:omit-tag="">Delete results of candidate</span>
msgid "delete_results"
msgstr "Supprimer le résultat du candidat"

#. <span i18n:translate="directions" tal:omit-tag="">Directions:</span>
msgid "directions"
msgstr "Remarques:"

#. widget=TextAreaWidget(
#. label='Directions',
#. label_msgid='directions_label',
#. description='Some content that all the questions in this folder refer to. You can also '\
#. + 'enter a text which helps the candidates to better understand the questions.',
#. description_msgid='directions_tool_tip',
#. i18n_domain='plone'),
#. label_#msgid='directions_label',
#. description='Some content that all the questions in this folder refer to. You can also '#.     + 'enter a text which helps the candidates to better understand the questions.',
#. description_#msgid='directions_tool_tip',
msgid "directions_label"
msgstr "Remarques"

msgid "directions_tool_tip"
msgstr "Un texte auquel toutes les questions dans ce classeur font référence ou un texte qui aide la compréhension des question."

#. <span i18n:translate="edit_evaluation_scripts_delete"
#. tal:omit-tag="">Delete custom scoring script for type</span>
#. tal:omit-tag="">Delete custom evaluation script for type</span>
msgid "edit_evaluation_scripts_delete"
msgstr "Supprimer le script d'évaluation pour"

#. <label for="archetype_names" i18n:translate="edit_evaluation_scripts_label">Scoring Scripts</label>
#. <label for="archetype_names" i18n:translate="edit_evaluation_scripts_label">Evaluation Scripts</label>
msgid "edit_evaluation_scripts_label"
msgstr "Scripts d'évaluation"

#. <div class="formHelp" id="archetype_names_help" i18n:translate="edit_evaluation_scripts_tool_tip">
#. The classes which use custom scoring scripts.
#. </div>
#. The classes which use custom evaluation scripts.
msgid "edit_evaluation_scripts_tool_tip"
msgstr "Les classes qui utilsent des scripts d'évaluation."

#. Default: The <%s> element must not be empty. Skipping invalid <%s> element.
#: ./qti.py, 1455
msgid "error_empty"
msgstr "L'élément <%s> ne doit pas être vide, l'élément <%s> sera ignoré."

#. msg = context.translate(\
#. msgid   = 'errors_occurred',\
#. domain  = I18N_DOMAIN,\
#. default = 'The following error(s) occurred:') + ' ' + errors
#. msg = context.translate(#.     #msgid   = 'errors_occurred',#.     domain  = I18N_DOMAIN,#.     default = 'The following error(s) occurred:') + ' ' + errors
#: Script (Python) "importTest"
msgid "errors_occurred"
msgstr "Erreur :"

#. widget=BooleanWidget(
#. label='Exam Mode'
#. label_msgid='exam_mode_label',
#. description='If you want to use this test as an exam, this box has to be checked. If you '\
#. + 'want to give the candidates immediate feedback and enable them to repeat the test, '\
#. + 'uncheck this box.',
#. description_msgid='exam_mode_tool_tip',
#. i18n_domain='plone'),
#. label_#msgid='exam_mode_label',
#. description='If you want to use this test as an exam, this box has to be checked. If you '#.     + 'want to give the candidates immediate feedback and enable them to repeat the test, '#.     + 'uncheck this box.',
#. description_#msgid='exam_mode_tool_tip',
msgid "exam_mode_label"
msgstr "Mode d'examen"

#, fuzzy
msgid "exam_mode_tool_tip"
msgstr "Si vous voulez utilisez ce test pour un examen, sélectionnez ce bouton ..."

#. Default: Expected Length
#: ./QuestionTypes/ExtendedTextQuestion.py, 71
msgid "expected_length_label"
msgstr "Longeur prévue"

#. Default: You can set the number of words you expect the candidate's answer to have.
#: ./QuestionTypes/ExtendedTextQuestion.py, 74
msgid "expected_length_tool_tip"
msgstr "Vous pouvez indiquer le nombre des mots prévu pour la réponse."

#. errors.write( '\n' + multipleChoiceTestInstance.translate(
#. msgid   = 'expected_string', \
#. domain  = 'llsMultipleChoice', \
#. default = 'Input must be str or unicode, not %s.') \
#. % str(type(string)) )
#. #msgid   = 'expected_string', #.     domain  = 'llsMultipleChoice', #.     default = 'Input must be str or unicode, not %s.') #.     % str(type(string)) )
#: qti.py
msgid "expected_string"
msgstr "L'entrée doit être str ou unicode sein, mais pas %s."

#. errors.write( '\n' + multipleChoiceTestInstance.translate(\
#. msgid   = 'expected_zip', \
#. domain  = 'llsMultipleChoice', \
#. default = 'Input must be ZipFile, not %s.') \
#. % str(type(zipFileObject)) )
#. errors.write( '\n' + multipleChoiceTestInstance.translate(#.     #msgid   = 'expected_zip', #.     domain  = 'llsMultipleChoice', #.     default = 'Input must be ZipFile, not %s.') #.     % str(type(zipFileObject)) )
#: qti.py
msgid "expected_zip"
msgstr "L'entrée doit être du type ZipFile, mais pas du type %s."

#. msg = context.translate(
#. msgid   = 'exportResults_no_permission',
#. domain  = 'llsMultipleChoice',
#. default = 'You do not have permission to export results.')
#. #msgid   = 'exportResults_no_permission',
msgid "exportResults_no_permission"
msgstr "Vous n'avez pas la permission pour exporter les résultats."

#. errors.write('\n' + context.translate(
#. msgid   = 'export_assessment_item_type_error',
#. domain  = I18N_DOMAIN,
#. default = 'Cannot export item "%s". Unsupported type "%s".'
#. ) % (context.str(obj.title_or_id()), context.str(obj.archetype_name)))
#. #msgid   = 'export_assessment_item_type_error',
#: qti.py
msgid "export_assessment_item_type_error"
msgstr "« %s » ne peut pas être importé : Le type « %s » n'est pas supporté."

#. Default: Ignore errors during export.
#: ./skins/llsMultipleChoice/test_import_export.pt, 113
msgid "export_ignore_errors"
msgstr "Ignorer erreurs pendant l'export."

#. <span i18n:translate="export_test_legend"
#. tal:omit-tag="">
#. <span i18n:name="itemtype">
#. <span i18n:domain="plone"
#. i18n:translate=""
#. tal:content="here/archetype_name"
#. tal:omit-tag="">Item type</span>
#. </span>
#. Export
#: skins/llsMultipleChoice/test_import_export.pt
msgid "export_test_legend"
msgstr "Exporter un ${itemtype}"

#. errors.write( '\n' + ( multipleChoiceTestInstance.translate(\
#. msgid   = 'extraction_error', \
#. domain  = 'llsMultipleChoice', \
#. default = 'Cannot extract the file "%s". An error occurred: %s') \
#. % (manifestFnList[0], str(e)) ) )
#. errors.write( '\n' + ( multipleChoiceTestInstance.translate(#.     #msgid   = 'extraction_error', #.     domain  = 'llsMultipleChoice', #.     default = 'Cannot extract the file "%s". An error occurred: %s') #.         % (manifestFnList[0], str(e)) ) )
#: qti.py
msgid "extraction_error"
msgstr "Le fichier « %s » ne peut être pas extrait. Erreur : %s"

#. <tal:block tal:condition="not: answer/isCorrect"><span
#. i18n:translate="false"
#. tal:omit-tag="">false</span></tal:block>
msgid "false"
msgstr "faux"

#. Default: Your results are not displayed because feedback is disabled.
#: ./skins/llsMultipleChoice/result_view.pt, 136
msgid "feedback_not_allowed"
msgstr "Vos résultat ne sont pas affichés parceque le test est en mode d'examen."

#. errors.write( '\n' + ( multipleChoiceTestInstance.translate(\
#. msgid   = 'file_exists', \
#. domain  = 'llsMultipleChoice', \
#. default = 'A file named "%s" already exits.') % fileName ) )
#. errors.write( '\n' + ( multipleChoiceTestInstance.translate(#.     #msgid   = 'file_exists', #.     domain  = 'llsMultipleChoice', #.     default = 'A file named "%s" already exits.') % fileName ) )
#: qti.py
msgid "file_exists"
msgstr "Il y'a déjà un fichier nommé « %s »."

#. msg = context.translate(\
#. msgid   = 'file_imported',\
#. domain  = I18N_DOMAIN,\
#. default = 'The file has been imported.')
#. msg = context.translate(#.     #msgid   = 'file_imported',#.     domain  = I18N_DOMAIN,#.     default = 'The file has been imported.')
#: Script (Python) "importTest"
msgid "file_imported"
msgstr "Le fichier a été importé."

#. msg = context.translate(\
#. msgid   = 'file_read_error',\
#. domain  = I18N_DOMAIN,\
#. default = 'The file could not be read.')
#. msg = context.translate(#.     #msgid   = 'file_read_error',#.     domain  = I18N_DOMAIN,#.     default = 'The file could not be read.')
#: Script (Python) "uploadEvaluationScript"
#: MultipleChoiceTest.processQTIImport()
msgid "file_read_error"
msgstr "Le fichier ne pouvait pas été lu."

#. errors.write( context.str('\n') + context.translate(\
#. msgid   = 'file_unexpected_error',\
#. domain  = I18N_DOMAIN,\
#. default = 'Could not import file "%s". An unexpected error has occurred: %s') % (context.str(fileName), context.str(e)) )
#. errors.write( context.str('\n') + context.translate(#.     #msgid   = 'file_unexpected_error',#.     domain  = I18N_DOMAIN,#.     default = 'Could not import file "%s". An unexpected error has occurred: %s') % (context.str(fileName), context.str(e)) )
#: qti.py
msgid "file_unexpected_error"
msgstr "Le fichier « %s » ne pouvait pas être importé. Erreur imprévu : %s"

#. errors.write( context.str('\n') + context.translate(\
#. msgid   = 'file_unicode_error',\
#. domain  = I18N_DOMAIN,\
#. default = 'The file name "%s" contains non-ASCII characters. The file will be imported under the id "%s".') % (context.str(oldId), context.str(id)) )
#. errors.write( context.str('\n') + context.translate(#.     #msgid   = 'file_unicode_error',#.     domain  = I18N_DOMAIN,#.     default = 'The file name "%s" contains non-ASCII characters. The file will be imported under the id "%s".') % (context.str(oldId), context.str(id)) )
#: qti.py
msgid "file_unicode_error"
msgstr "Le nom de fichier « %s » contient des charactères non-ASCII; au lieu de ce nom l'identification « %s » sera utilisé."

#. <th i18n:translate="finished">Finished</th>
msgid "finished"
msgstr "Fin"

#. <span tal:replace="intPoints"/><span i18n:translate="fraction_delimiter" tal:omit-tag="">.</span><span tal:replace="fracPoints"/>
msgid "fraction_delimiter"
msgstr ","

#. Default: Grade
#: ./MultipleChoiceTest.py, 107
msgid "grade"
msgstr "Note"

#. Default: Grading Scale
#: MultipleChoiceTest.py
msgid "grading_scale_label"
msgstr "Échelle de notation"

#. Default: Grades are issued according to the following scale of point values.  The minimum score can be specified as a percentage or as an absolute value.  Leave the minimum score column of the last row empty; this grade will be used for all scores which are not covered by one of the other entries.
#: MultipleChoiceTest.py
msgid "grading_scale_tool_tip"
msgstr "La table suivante vous permet de définir les notes qui correspondent à certains nombres de points. Le nombre de points minimum peut être exprimé en pourcentage ou en absolu. Dans la dernière ligne, ne donnez pas un nombre de points; cette note sera utilisée pour les résultats pour lequels n'existe pas d'autre entrée."

#. <h1 i18n:translate="heading_import_export">
#. Import/Export
#. <span i18n:name="itemtype">
#. <span i18n:domain="plone"
#. i18n:translate=""
#. tal:content="here/archetype_name"
#. tal:omit-tag="">Item type</span>
#. </span>
#. </h1>
#: skins\llsMultipleChoice\test_import_export.pt
msgid "heading_import_export"
msgstr "Importer/exporter un ${itemtype}"

#. <span style="color:red;" i18n:translate="i_dont_know">I don't know. (The question will be evaluated as if you had given no answer.)</span>
msgid "i_dont_know"
msgstr "Je ne sais pas (cette question sera considerée inrépondu)."

#. errors.write( context.str('\n') + context.translate(\
#. msgid   = 'identifier_unicode_error',\
#. domain  = I18N_DOMAIN,\
#. default = 'The identifier "%s" contains non-ASCII characters. The item will be imported under the id "%s".') % (context.str(oldId), context.str(id)) )
#. q = createObject(context, typeName, id=id)
#. errors.write( context.str('\n') + context.translate(#.     #msgid   = 'identifier_unicode_error',#.     domain  = I18N_DOMAIN,#.     default = 'The identifier "%s" contains non-ASCII characters. The item will be imported under the id "%s".') % (context.str(oldId), context.str(id)) )
#: qti.py
msgid "identifier_unicode_error"
msgstr "L'identification « %s » contient des charactères non-ASCII; au lieu de ce nom l'identification « %s » sera utilisé."

#. <label for="file" i18n:translate="import_file_label">QTI File</label>
#: skins\llsMultipleChoice\test_import_export.pt
msgid "import_file_label"
msgstr "Fichier QTI"

#. <span i18n:translate="import_test_legend"
#. tal:omit-tag="">
#. <span i18n:name="itemtype">
#. <span i18n:domain="plone"
#. i18n:translate=""
#. tal:content="here/archetype_name"
#. tal:omit-tag="">Item type</span>
#. </span>
#. Import
#: skins\llsMultipleChoice\test_import_export.pt
msgid "import_test_legend"
msgstr "Importer un ${itemtype}"

# <div class="formHelp" i18n:translate="import_test_tool_tip">The
# name of the assessment item or package you want to import.</div>
#: skins\llsMultipleChoice\test_import_export.pt
msgid "import_test_tool_tip"
msgstr "Le nom du assessment item ou du package que vous voulez importer."

#. BooleanField('instantFeedback',
#. required=False,
#. default=0,
#. accessor='isInstantFeedback',
#. widget=BooleanWidget(
#. label='Instant Feedback',
#. label_#msgid='instant_feedback_label',
#. description='If you want to give the candidates instant feedback '#.                + 'check this box.',
#. description_#msgid='instant_feedback_tool_tip',
#. i18n_domain='llsMultipleChoice'),
#. ),
msgid "instant_feedback_label"
msgstr "Présentation immédiate des résultats"

msgid "instant_feedback_tool_tip"
msgstr "Choisissez cette option si les résultats du test doivent être présentés aux candidats immédiatement après qu'ils aient passés le test."

#. Default: The test was modified after these answers had been submitted. These test results are therefore invalid.
#: ./skins/llsMultipleChoice/result_view.pt, 41
msgid "invalid"
msgstr "Le test a été modifié après ces réponses ont été soumises. Par conséquent, les réponses ont été déclarées nulles."

#. Default: The expected length "%s" is invalid.
#: ./qti.py, 785
msgid "invalid_expected_length"
msgstr "Longeur prévue « %s » illégale."

#. Default: Not a percentage or an absolute value: %s
#: ./MultipleChoiceTest.py, 131
msgid "invalid_minimum_score"
msgstr "Le valeur « %s » n'est pas un pourcentage ni un valeur absolu."

#. Default: Not a percentage or an absolute value: %s. Skipping invalid <%s> element.
#: ./qti.py, 1484
msgid "invalid_minimum_score_qti"
msgstr "Le valeur « % » n'est pas un pourcentage ni un valeur absolu, l'élément <%s> sera ignoré."

#. Default: Please enter a number or leave the field empty.
#: ./skins/llsMultipleChoice/result_grade_validate.vpy, 50
msgid "invalid_score"
msgstr "Entrez un nombre ou laissez la zone d'entrée vide."

#. Default: The select count "%s" is invalid.
#: ./qti.py, 1245
msgid "invalid_select_count"
msgstr "Le nombre des choix « %s » est illégal."

#. errors.write('\n' + context.translate(
#. msgid   = 'invalid_weight',
#. domain  = I18N_DOMAIN,
#. default = 'The weight "%s" is invalid.'
#. ) % context.str(weight))
#. #msgid   = 'invalid_weight',
#: qti.py
msgid "invalid_weight"
msgstr "Le pois « %s » n'est pas valide."

#. msg = context.translate(\
#. msgid   = 'item_deleted',\
#. domain  = I18N_DOMAIN,\
#. default = 'Item deleted.')
#. msg = context.translate(#.     #msgid   = 'item_deleted',#.     domain  = I18N_DOMAIN,#.     default = 'Item deleted.')
#: Script (Python) "deleteResults"
msgid "item_deleted"
msgstr "Entrée supprimée."

#. errors.write( '\n' + ( context.translate(\
#. msgid   = 'item_exists', \
#. domain  = I18N_DOMAIN, \
#. default = 'An item named "%s" already exits.') \
#. % (context.str(assessmentItemIdentifier)) ) )
#. errors.write( '\n' + ( context.translate(#.     #msgid   = 'item_exists', #.     domain  = I18N_DOMAIN, #.     default = 'An item named "%s" already exits.') #.     % (context.str(assessmentItemIdentifier)) ) )
#: qti.py
msgid "item_exists"
msgstr "Il y a déjà une entrée nommée « %s »."

#. msg = context.translate(\
#. msgid   = 'items_deleted',\
#. domain  = I18N_DOMAIN,\
#. default = 'Items deleted.')
#. msg = context.translate(#.     #msgid   = 'items_deleted',#.     domain  = I18N_DOMAIN,#.     default = 'Items deleted.')
#: Script (Python) "deleteResults"
msgid "items_deleted"
msgstr "Entrées supprimées."

#. Default: [Download]
#: ./skins/llsMultipleChoice/test_results.pt, 208
msgid "label_action_download"
msgstr "[Télécharger]"

#. Default: [Grade]
#: ./skins/llsMultipleChoice/test_results.pt, 202
msgid "label_action_grade"
msgstr "[Noter]"

#. Default: [View]
#: ./skins/llsMultipleChoice/test_results.pt, 196
msgid "label_action_view"
msgstr "[Afficher]"

#. Default: Actions
#: ./skins/llsMultipleChoice/test_results.pt, 91
msgid "label_actions"
msgstr "Actions"

#. Default: Grade
#: ./skins/llsMultipleChoice/test_results.pt, 86
msgid "label_grade"
msgstr "Note"

#. Default: "Released"
#: Result.py
msgid "label_released"
msgstr "Publié"

#. <th i18n:translate="link_to_test">Link to test</th>
msgid "link_to_test"
msgstr "Lien au test"

#: MultipleChoiceTest.py
msgid "mean"
msgstr "Moyenne"

#: MultipleChoiceTest.py
msgid "median"
msgstr "Médiane"

#. Default: The minimum score column of the last row must be empty.
#: ./MultipleChoiceTest.py, 121
msgid "minimum_score_not_empty"
msgstr "Ne donnez pas un nombre de points dans la dernière ligne."

#. Default: The minimum score column of the last row of the <%s> element must be empty. Ignoring last score.
#: ./qti.py, 1466
msgid "minimum_score_not_empty_qti"
msgstr "La colonne « nombre de points minimum » doit être vide dans la dernière ligne, le contenu sera ignoré."

#. errors.write( '\n' + ( multipleChoiceTestInstance.translate(\
#. msgid   = 'multiple_manifest', \
#. domain  = 'llsMultipleChoice', \
#. default = 'The package contains more than one file called "%s".') % MANIFEST_FILE_NAME ) )
#. errors.write( '\n' + ( multipleChoiceTestInstance.translate(#.     #msgid   = 'multiple_manifest', #.     domain  = 'llsMultipleChoice', #.     default = 'The package contains more than one file called "%s".') % MANIFEST_FILE_NAME ) )
#: qti.py
msgid "multiple_manifest"
msgstr "Le package contien plus qu'un fichier nommé « %s »."

#. <th i18n:translate="name">Name</th>
msgid "name"
msgstr "Nom"

#. errors.write( '\n' + multipleChoiceTestInstance.translate(\
#. msgid   = 'no_choiceInteraction',\
#. domain  = 'llsMultipleChoice',\
#. default = 'Expected a <%s> element. Got "%s".') % (CHOICE_INTERACTION, choiceInteractionElement.toxml() ))
#. errors.write( '\n' + multipleChoiceTestInstance.translate(#.     #msgid   = 'no_choiceInteraction',#.     domain  = 'llsMultipleChoice',#.     default = 'Expected a <%s> element. Got "%s".') % (CHOICE_INTERACTION, choiceInteractionElement.toxml() ))
#: qti.py
msgid "no_choiceInteraction"
msgstr "J'ai cherché un élément <%s>, mais j'ai réçu « %s »."

#. errors.write( '\n' + multipleChoiceTestInstance.translate(\
#. msgid   = 'no_choice_interaction',\
#. domain  = 'llsMultipleChoice',\
#. default = 'Did not find any <%s> elements.') % CHOICE_INTERACTION )
#. errors.write( '\n' + multipleChoiceTestInstance.translate(#.     #msgid   = 'no_choice_interaction',#.     domain  = 'llsMultipleChoice',#.     default = 'Did not find any <%s> elements.') % CHOICE_INTERACTION )
#: qti.py
msgid "no_choice_interaction"
msgstr "Je n'ai pas trouvé des élements <%s>."

#. <p tal:condition="not: participants" i18n:translate="no_graded_results">
#. There are no graded results for this test.
#. </p>
msgid "no_graded_results"
msgstr "Il n'y a pas de résultats pour ce test."

#. Default: Did not find any elements of type %s.
#: ./qti.py, 960
msgid "no_interaction"
msgstr "Pas d'éléments du type %s."

#. errors.write( '\n' + ( multipleChoiceTestInstance.translate(\
#. msgid   = 'no_interaction_type', \
#. domain  = 'llsMultipleChoice', \
#. default = 'Resource specifies no interaction type. Skipping item "%s (%s)".') \
#. % (resourceTitle, resourceFileName) ) )
#. errors.write( '\n' + ( multipleChoiceTestInstance.translate(#.     #msgid   = 'no_interaction_type', #.     domain  = 'llsMultipleChoice', #.     default = 'Resource specifies no interaction type. Skipping item "%s (%s)".') #.     % (resourceTitle, resourceFileName) ) )
#: qti.py
msgid "no_interaction_type"
msgstr "La ressource ne spécifie pas de type d'interaction. La ressource \\\"%s (%s)\\\" sera ignorée."

#. errors.write( '\n' + multipleChoiceTestInstance.translate(\
#. msgid   = 'no_item_body',\
#. domain  = 'llsMultipleChoice',\
#. default = 'Expected exactly one <%s> element.') % ITEM_BODY )
#. errors.write( '\n' + multipleChoiceTestInstance.translate(#.     #msgid   = 'no_item_body',#.     domain  = 'llsMultipleChoice',#.     default = 'Expected exactly one <%s> element.') % ITEM_BODY )
#: qti.py
msgid "no_item_body"
msgstr "Ne plus qu'un élément <%s> est acceptable."

#. errors.write( '\n' + ( multipleChoiceTestInstance.translate(\
#. msgid   = 'no_manifest', \
#. domain  = 'llsMultipleChoice', \
#. default = 'The package must contain a manifest file called "%s".') % MANIFEST_FILE_NAME ) )
#. errors.write( '\n' + ( multipleChoiceTestInstance.translate(#.     #msgid   = 'no_manifest', #.     domain  = 'llsMultipleChoice', #.     default = 'The package must contain a manifest file called "%s".') % MANIFEST_FILE_NAME ) )
#: qti.py
msgid "no_manifest"
msgstr "Le package doit contenir un fichier manifest nommé « %s »."

#. errors.write( '\n' + ( context.translate(\
#. msgid   = 'no_qti',\
#. domain  = I18N_DOMAIN,\
#. default = 'Invalid QTI document. The name of the root element has to '\
#. + 'be "%s", not "%s".') % (ASSESSMENT_ITEM, dom.documentElement.localName) ) )
#. errors.write( '\n' + ( context.translate(#.     #msgid   = 'no_qti',#.     domain  = I18N_DOMAIN,#.     default = 'Invalid QTI document. The name of the root element has to '#.         + 'be "%s", not "%s".') % (ASSESSMENT_ITEM, dom.documentElement.localName) ) )
#: qti.py
msgid "no_qti"
msgstr "Document QTI invalide. Le nom de l'élément racine doit être « %s », mais pas « %s »."

#. <p tal:condition="isEmpty" i18n:translate="no_questions">
#. This test contains no questions.</p>
msgid "no_questions"
msgstr "Ce test ne contient aucunes questions."

#. <span i18n:translate="no_repetition"
#. tal:omit-tag="">
#. You may not submit it again.
#. </span>
msgid "no_repetition"
msgstr "Vous ne pouvez pas le repasser."

#. Default: There are no results for this test.
#: ./skins/llsMultipleChoice/test_results.pt, 276
msgid "no_results"
msgstr "Il n'y a pas de résultats pour ce test."

#. Default: Not graded
#: ./skins/llsMultipleChoice/pointsquestion_view.pt, 42
msgid "not_graded"
msgstr "Ne pas noté"

#. msg = context.translate(\
#. msgid   = 'not_submit_again',\
#. domain  = I18N_DOMAIN,\
#. default = 'You may not submit the test again.')
#. msg = context.translate(#.     #msgid   = 'not_submit_again',#.     domain  = I18N_DOMAIN,#.     default = 'You may not submit the test again.')
#: Script (Python) "submitTest"
msgid "not_submit_again"
msgstr "Vous ne pouvez pas repasser ce test."

#. <tal:condition condition="not: hasSubmitted"><span
#. i18n:translate="not_submitted" style="color:red;">Not submitted</span></tal:condition>
msgid "not_submitted"
msgstr "Pas encore passé"

#. msg += '\n' + context.translate(\
#. msgid   = 'nothing_added',\
#. domain  = I18N_DOMAIN,\
#. default = 'Nothing has been added.')
#. msg += '\n' + context.translate(#.     #msgid   = 'nothing_added',#.     domain  = I18N_DOMAIN,#.     default = 'Nothing has been added.')
#: Script (Python) "importTest"
msgid "nothing_added"
msgstr "Rien n'été ajouté."

#. IntegerField("numberOfRandomAnswers",
#. default=-1,
#. read_permission=PERMISSION_INTERROGATOR,
#. widget=IntegerWidget(
#. label='Number of Random Answers',
#. label_msgid='number_of_random_answers_label',
#. description='The number of answers which are randomly selected when a new test is '\
#. + 'generated for a candidate. (This only works if &quot;Randomize Answer Order&quot; '\
#. + 'is checked.)  A value &lt;= 0 means that all answers will be used.',
#. description_msgid='number_of_random_answers_tool_tip',
#. i18n_domain='llsMultipleChoice'),
#. ),
#. label_#msgid='number_of_random_answers_label',
#. description='The number of answers which are randomly selected when a new test is '#.        + 'generated for a candidate. (This only works if &quot;Randomize Answer Order&quot; '#.        + 'is checked.)  A value &lt;= 0 means that all answers will be used.',
#. description_#msgid='number_of_random_answers_tool_tip',
msgid "number_of_random_answers_label"
msgstr "Nombre des réponses tirées au sort"

msgid "number_of_random_answers_tool_tip"
msgstr "Le nombre de réponses tirées au sort quand un test est produit pour\nun candidat. L'option « ordre tiré au sort » doit être selectionnée. Une entrée &#x2266;0 indique que toutes les réponses seront utilisées."

#. IntegerField("numberOfRandomQuestions",
#. required=False,
#. default=-1,
#. widget=IntegerWidget(
#. label='Number of Random Questions',
#. label_msgid='number_of_random_questions_label',
#. description='The number of questions which are randomly selected when a new test is '\
#. + 'generated for a candidate. (This only works if &quot;Randomize Question Order&quot; '\
#. + 'is checked.) A value &lt;= 0 means that all questions will be used.',
#. description_msgid='number_of_random_questions_tool_tip',
#. i18n_domain='llsMultipleChoice'),
#. ),
#. label_#msgid='number_of_random_questions_label',
#. description='The number of questions which are randomly selected when a new test is '#.        + 'generated for a candidate. (This only works if &quot;Randomize Question Order&quot; '#.        + 'is checked.) A value &lt;= 0 means that all questions will be used.',
#. description_#msgid='number_of_random_questions_tool_tip',
msgid "number_of_random_questions_label"
msgstr "Nombre de questions tirées au sort"

msgid "number_of_random_questions_tool_tip"
msgstr "Le nombre de questions tirées au sort quand un test est produit pour un candidat. L'option « ordre tiré au sort » doit être selectionnée. Une entrée &#x2266;0 indique que toutes les questions seront utilisées.\n"

#. msg += '\n' + context.translate(\
#. msgid   = 'objects_added',\
#. domain  = I18N_DOMAIN,\
#. default = 'The following objects have been added:') + ' '
#. msg += '\n' + context.translate(#.     #msgid   = 'objects_added',#.     domain  = I18N_DOMAIN,#.     default = 'The following objects have been added:') + ' '
#: Script (Python) "importTest"
msgid "objects_added"
msgstr "Les objets suivants ont étés ajoutés :"

#. Default: One Question per Page
#: MultipleChoiceTest.py
msgid "one_per_page_label"
msgstr "Une question par page"

#. Default: Allow Navigation
#: MultipleChoiceTest.py
msgid "one_per_page_nav_label"
msgstr "Permettre la navigation"

#. Default: Lets candidates answer questions in an arbitrary order when the test is in one-question-per-page-mode.
#: MultipleChoiceTest.py
msgid "one_per_page_nav_tool_tip"
msgstr "Si l'option « Une question par page » est activée, permet les candidats à choisir l'ordre dans lequel ils répondent aux questions."

#. Default: If checked, each question/question group is displayed on a separate page.
#: MultipleChoiceTest.py
msgid "one_per_page_tool_tip"
msgstr "Affiche chaque question/groupe de questions sur une page individuelle."

#. <h2 i18n:translate="overview">Overview</h2>
msgid "overview"
msgstr "Résumé"

#. errors.write( '\n' + multipleChoiceTestInstance.translate(\
#. msgid   = 'parse_error',\
#. domain  = 'llsMultipleChoice',\
#. default = 'A parse error occurred in "%s": %s') \
#. % (str(string), str(e) ) )
#. errors.write( '\n' + multipleChoiceTestInstance.translate(#.     #msgid   = 'parse_error',#.     domain  = 'llsMultipleChoice',#.     default = 'A parse error occurred in "%s": %s') #.     % (str(string), str(e) ) )
#: qti.py
msgid "parse_error"
msgstr "Erreur de parseur dans « %s » : %s"

#. <label for="participants" i18n:translate="participants_label">Candidates</label>
msgid "participants_label"
msgstr "candidats"

#. <div class="formHelp" id="participants_help" i18n:translate="participants_tool_tip">
#. The user IDs of the candidates who have already seen or taken this test.
#. </div>
msgid "participants_tool_tip"
msgstr "Les IDs des candidats qui ont vu ou passé le test."

#. <span tal:condition="python:question.getPoints() == 1"
#. i18n:translate="point"
#. tal:omit-tag="">Point</span>
msgid "point"
msgstr "point"

#. <span tal:condition="python:question.getPoints() != 1"
#. i18n:translate="points"
#. tal:omit-tag="">Points</span>
msgid "points"
msgstr "points"

#. Default: The number of points awarded for this answer. You can leave the field empty if you want to review the answer later.
#: ./skins/llsMultipleChoice/pointsquestion_view.pt, 92
msgid "points_help"
msgstr "Le nombre de points donné pour cette réponse.  Vous pouvez le laisser vide si vous voulez noter la réponse plus tard."

#. widget=IntegerWidget(
#. label='Points',
#. label_msgid='points_label',
#. description='The number of points assigned to this question.',
#. description_msgid='points_tool_tip',
#. i18n_domain='plone'),
#. label_#msgid='points_label',
#. description_#msgid='points_tool_tip',
msgid "points_label"
msgstr "Points"

msgid "points_tool_tip"
msgstr "Le nombre de points pour cette question."

#. widget=TextAreaWidget(
#. label='Question',
#. label_msgid='question_label',
#. description='The question text. This is what the candidate will see.',
#. description_msgid='question_tool_tip',
#. i18n_domain='plone'),
#. label_#msgid='question_label',
#. description_#msgid='question_tool_tip',
msgid "question_label"
msgstr "Question"

msgid "question_tool_tip"
msgstr "Le texte de la question qui est présenté au candidat."

#. <h2 i18n:translate="questions">Questions</h2>
msgid "questions"
msgstr "questions"

#. BooleanField("randomOrder",
#. accessor='isRandomOrder',
#. required=False,
#. default=1,
#. widget=BooleanWidget(
#. label='Randomize Answer Order',
#. label_msgid='randomize_answer_order_label',
#. description='Check this box if you want the answers to this question '\
#. + 'to appear in a different, random order for each candidate. Otherwise the '\
#. + 'same order as in the &quot;contents&quot;-view will be used.',
#. description_msgid='randomize_answer_order_tool_tip',
#. i18n_domain='llsMultipleChoice'),
#. ),
#. label_#msgid='randomize_answer_order_label',
#. description='Check this box if you want the answers to this question '#.        + 'to appear in a different, random order for each candidate. Otherwise the '#.        + 'same order as in the &quot;contents&quot;-view will be used.',
#. description_#msgid='randomize_answer_order_tool_tip',
msgid "randomize_answer_order_label"
msgstr "Ordre de réponses tiré au sort"

msgid "randomize_answer_order_tool_tip"
msgstr "Choisissez cette option si l'ordre des réponses pour cette question\ndoit être tiré au sort pour chaque candidat. Sinon, l'ordre défini est\nutilisé.\n"

#. BooleanField("randomOrder",
#. accessor='isRandomOrder',
#. required=False,
#. default=0,
#. widget=BooleanWidget(
#. label='Randomize Question Order',
#. label_msgid='randomize_question_order_label',
#. description='Check this box if you want the questions in this container '\
#. + 'to appear in a different, random order for each candidate. Otherwise the '\
#. + 'same order as in the &quot;contents&quot;-view will be used.',
#. description_msgid='randomize_question_order_tool_tip',
#. i18n_domain='llsMultipleChoice'),
#. ),
#. label_#msgid='randomize_question_order_label',
#. description='Check this box if you want the questions in this container '#.        + 'to appear in a different, random order for each candidate. Otherwise the '#.        + 'same order as in the &quot;contents&quot;-view will be used.',
#. description_#msgid='randomize_question_order_tool_tip',
msgid "randomize_question_order_label"
msgstr "Ordre des questions tiré au sort"

msgid "randomize_question_order_tool_tip"
msgstr "Choisissez cette option si l'ordre des questions dans ce classeur doit être tiré au sort pour chaque candidat. Sinon, l'ordre défini sera utilisé."

#. errors.write( '\n' + ( multipleChoiceTestInstance.translate(\
#. msgid   = 'read_error', \
#. domain  = 'llsMultipleChoice', \
#. default = 'Cannot read the file "%s". An error occurred: %s') \
#. % (fileName, str(e)) ) )
#. errors.write( '\n' + ( multipleChoiceTestInstance.translate(#.     #msgid   = 'read_error', #.     domain  = 'llsMultipleChoice', #.     default = 'Cannot read the file "%s". An error occurred: %s') #.         % (fileName, str(e)) ) )
#: qti.py
msgid "read_error"
msgstr "Le fichier « %s » ne peut pas être lu. Erreur : %s"

#. Default: Reference
#: MultipleChoiceReference.py
msgid "reference_label"
msgstr "Référence"

#. Default: "Select a question or a question group from another test."
#: MultipleChoiceReference.py
msgid "reference_tool_tip"
msgstr "Choisissez une question ou une groupe de questions d'un autre test."

#. resultsString = context.translate(\
#. msgid   = 'results',\
#. domain  = I18N_DOMAIN,\
#. default = 'results')
#. filename = quote(context.title_or_id()) + SPACE_REPLACER + resultsString + '.' + format
#. resultsString = context.translate(#.     #msgid   = 'results',#.     domain  = I18N_DOMAIN,#.     default = 'results')
#: Script (Python) "exportResults"
msgid "results"
msgstr "Résultats"

#. <h1>
#. <span i18n:translate="results_for" tal:omit-tag="">Results for</span>
#. <span tal:replace="here/title_or_id"/>
#. </h1>
msgid "results_for"
msgstr "Résultats pour"

#. <h2><span i18n:translate="results_of" tal:omit-tag="">Results of</span> <span tal:replace="submitterId"/></h2>
msgid "results_of"
msgstr "Résultat de"

#. Default: <h2 i18n:translate="results_of_name">Results of ${candidateName}:</h2>
#: skins/llsMultipleChoice/result_view.pt
msgid "results_of_name"
msgstr "Résultats pour ${candidateName} :"

#. msg = context.translate(\
#. msgid   = 'results_reset',\
#. domain  = I18N_DOMAIN,\
#. default = 'Your results have been reset.')
#. msg = context.translate(#.     #msgid   = 'results_reset',#.     domain  = I18N_DOMAIN,#.     default = 'Your results have been reset.')
#: Script (Python) "resetResult"
msgid "results_reset"
msgstr "Vos résultats ont étés annulés."

#. <p>
#. <span i18n:translate="score"
#. tal:omit-tag="">Score:</span>
#. <strong><span tal:replace="python:here.getCandidatePoints(submitterId);">candidate's points</span>/<span tal:replace="python:here.getPossiblePoints(submitterId);">possible points</span></strong>
#. </p>
msgid "score"
msgstr "Nombre de points:"

#. Default: This score is higher than the maximum score for this question, %s.
#: ./skins/llsMultipleChoice/result_grade_validate.vpy, 61
msgid "score_too_high"
msgstr "Le nombre de points est plus grand que le nombre maximum pour cette question."

#. MultipleChoiceTest.py
#. Default: "All or Nothing"
msgid "scoring_fun_cruel_label"
msgstr "Tout ou rien"

#. MultipleChoiceTest.py
#. Default: "Guessing Correction"
msgid "scoring_fun_guessing_correction_label"
msgstr "Correction de l'effet du hasard"

#. MultipleChoiceTest.py
#. Default: "Scoring Function"
msgid "scoring_fun_label"
msgstr "Fonction d'évaluation"

#. MultipleChoiceTest.py
#. Default: "The way the score for a question is calculated."
msgid "scoring_fun_tool_tip"
msgstr "La méthode utilisée pour la calculation des points pour les questions."

#. msg = context.translate(
#. #msgid   = 'scoring_scripts_deleted',
#. domain  = I18N_DOMAIN,
#. default = 'Deleted custom scoring scripts for types: '
#: Script (Python) "deleteEvaluationScript"
msgid "scoring_scripts_deleted"
msgstr "Les scripts d'évaluation ont été supprimés pour les classes suivantes : "

#. msg = context.translate(\
#. msgid   = 'script_invalid',\
#. domain  = I18N_DOMAIN,\
#. default = 'The script is invalid. The following error occurred:') + ' ' + uploadErrorMessage
#. msg = context.translate(#.     #msgid   = 'script_invalid',#.     domain  = I18N_DOMAIN,#.     default = 'The script is invalid. The following error occurred:') + ' ' + uploadErrorMessage
#: Script (Python) "uploadEvaluationScript"
msgid "script_invalid"
msgstr "Le script n'est pas valide. Erreur :"

#. msg = context.translate(\
#. msgid   = 'script_uploaded',\
#. domain  = I18N_DOMAIN,\
#. default = 'The script has been uploaded.')
#. msg = context.translate(#.     #msgid   = 'script_uploaded',#.     domain  = I18N_DOMAIN,#.     default = 'The script has been uploaded.')
#: Script (Python) "uploadEvaluationScript"
msgid "script_uploaded"
msgstr "Le script est chargé."

#. <a
#. tal:condition="hasSubmitted"
#. tal:attributes="href string:test_results#result_${participantId}"
#. i18n:translate="see_test" >See test</a>
msgid "see_test"
msgstr "Voir le test"

#. selectMsg  python:here.translate(
#. msgid   = 'select',
#. domain  = 'llsMultipleChoice',
#. default = 'Select %s')
#. #msgid   = 'select',
msgid "select"
msgstr "Sélectionner %s"

#. msg = context.translate(\
#. msgid   = 'select_item_delete',\
#. domain  = I18N_DOMAIN,\
#. default = 'Please select one or more items to delete first.')
#. msg = context.translate(#.     #msgid   = 'select_item_delete',#.     domain  = I18N_DOMAIN,#.     default = 'Please select one or more items to delete first.')
#: Script (Python) "deleteResults"
msgid "select_item_delete"
msgstr "Sélectionnez une ou plusieurs entrées pour supprimer."

#. msg = context.translate(\
#. msgid   = 'select_item_export',\
#. domain  = I18N_DOMAIN,\
#. default = 'Please select one or more items to export first.')
#. msg = context.translate(#.     #msgid   = 'select_item_export',#.     domain  = I18N_DOMAIN,#.     default = 'Please select one or more items to export first.')
#: Script (Python) "exportResults"
msgid "select_item_export"
msgstr "Sélectionnez une ou plusieurs entrées pour l'exportation."

#. <th i18n:translate="started">Started</th>
msgid "started"
msgstr "Début"

# this is part of the filename of the exported statistics file
#. Default: statistics
#: skins/llsMultipleChoice/exportItemStatistics.py
msgid "statistics"
msgstr "Statistiques"

#. <h1>
#. <span i18n:translate="statistics_for" tal:omit-tag="">Results for</span>
#. <span tal:replace="here/title_or_id"/>
#. </h1>
msgid "statistics_for"
msgstr "Statistiques pour"

#: MultipleChoiceTest.py
msgid "stddev"
msgstr "Écart type"

#. msg = context.translate(\
#. msgid   = 'string_not_file',\
#. domain  = I18N_DOMAIN,\
#. default = 'Got a string, not a file to read.')
#. msg = context.translate(#.     #msgid   = 'string_not_file',#.     domain  = I18N_DOMAIN,#.     default = 'Got a string, not a file to read.')
#: Script (Python) "importTest" "uploadEvaluationScript"
msgid "string_not_file"
msgstr "L'argument doit être un fichier, mais c'est une chaîne de charactères."

#. Default: This test has not been submitted yet.
#: ./skins/llsMultipleChoice/result_view.pt, 128
msgid "test_not_submitted"
msgstr "Ce test n'est pas encore soumis."

#. <th i18n:translate="test_results_max_score">Max. Score</th>
msgid "test_results_max_score"
msgstr "Nombre maximum de points"

#. <th i18n:translate="test_results_score">Score</th>
msgid "test_results_score"
msgstr "Nombre de points"

#. <span i18n:translate="test_taken"
#. tal:omit-tag="">You have already taken this test.
#. </span>
msgid "test_taken"
msgstr "Vous avez déjà passé ce test."

#. Default: %H:%M:%S
#: ECQuizTool.py
msgid "time_delta_fmt"
msgstr ""

#. Default: Time Spent:
#: skins/llsMultipleChoice/basequestion_view.pt
msgid "time_spent"
msgstr "Temps utilisé:"

#. errors.write( '\n' + multipleChoiceTestInstance.translate(\
#. msgid   = 'too_many_elements',\
#. domain  = 'llsMultipleChoice',\
#. default = 'Expected at most one <%s> element. Skipping the following <%s> elements.') \
#. % (PROMPT, PROMPT) )
#. errors.write( '\n' + multipleChoiceTestInstance.translate(#.     #msgid   = 'too_many_elements',#.     domain  = 'llsMultipleChoice',#.     default = 'Expected at most one <%s> element. Skipping the following <%s> elements.') #.         % (PROMPT, PROMPT) )
#: qti.py
msgid "too_many_elements"
msgstr "Un élément <%s> au maximum, je saute les éléments <%s> suivants."

#. Default: "These test results have been released for viewing"
#: Result.py
msgid "tooltip_released_icon"
msgstr "Ces résultats ont été publiés"

#. <tal:block tal:condition="answer/isCorrect"><span
#. i18n:translate="true"
#. tal:omit-tag="">true</span></tal:block>
msgid "true"
msgstr "correct"

#. Default: Tutor-Graded
#: QuestionTypes/PointsQuestion.py
msgid "tutor_graded_label"
msgstr "Évaluation manuelle"

#. Default: If answers to this question are graded manually, mark this checkbox.
#: QuestionTypes/PointsQuestion.py
msgid "tutor_graded_tool_tip"
msgstr "Selectionnez ce bouton si les réponses à cette question seront évaluées manuellement."

# Original: Layout
#: QuestionTypes/ECQScaleQuestion.py
msgid "layout_label"
msgstr "Affichage des choix"

# Original: Select &quot;vertical&quot; if you want the choices to be listed from to top to bottom. Select &quot;horizontal&quot; if you want them to appear in a single row.
#: QuestionTypes/ECQScaleQuestion.py
msgid "layout_tool_tip"
msgstr "Choisissez « vertical » pour afficher les choix de haut en bas.  Choisissez « horizontal » pour les afficher sur une seule ligne."

# Original: Vertical
#: QuestionTypes/ECQScaleQuestion.py
msgid "layout_vertical_label"
msgstr "Vertical"

# Original: Horizontal
#: QuestionTypes/ECQScaleQuestion.py
msgid "layout_horizontal_label"
msgstr "Horizontal"

# Original: No selection.
#: skins/ECQuiz/ecq_scalequestion_view.cpt
msgid "no_selection"
msgstr "Pas de sélection"

#. errors.write( '\n' + multipleChoiceTestInstance.translate(\
#. msgid   = 'unexpected_error',\
#. domain  = 'llsMultipleChoice',\
#. default = 'An unexpected error has occurred in "%s": %s'\
#. ) % (functionName, str(e)))
#. errors.write( '\n' + multipleChoiceTestInstance.translate(#.                         #msgid   = 'unexpected_error',#.                         domain  = 'llsMultipleChoice',#.                         default = 'An unexpected error has occurred in "%s": %s'#.                     ) % (functionName, str(e)))
#: qti.py
msgid "unexpected_error"
msgstr "Erreur indéfini en « %s » : %s"

#. Default: An an unexpected has occurred.  The test could not be exported.
#: ./skins/llsMultipleChoice/exportTest.py, 59
msgid "unexpected_export_error"
msgstr "Erreur imprévu, l'export du test a échoué."

#. ERROR_FORMAT_MSG = context.translate(\
#. msgid   = 'unknown_format_export',\
#. domain  = I18N_DOMAIN,\
#. default = 'Unknown format. Cannot export.')
#. ERROR_FORMAT_MSG = context.translate(#.     #msgid   = 'unknown_format_export',#.     domain  = I18N_DOMAIN,#.     default = 'Unknown format. Cannot export.')
#: Script (Python) "exportResults"
msgid "unknown_format_export"
msgstr "Format inconnu, exportation non possible."

#. errors.write('\n' + context.translate(
#. msgid   = 'unresolved_reference',
#. domain  = I18N_DOMAIN,
#. default = 'There is no resource with the identifier "%s".'
#. 'The item cannot be imported.'
#. ) % context.str(identifierref))
#. #msgid   = 'unresolved_reference',
#: qti.py
msgid "unresolved_reference"
msgstr "Il n'y a pas de ressource avec l'identification « %s ». Le fichier ne peut pas être importé."

#. errors.write( '\n' + ( multipleChoiceTestInstance.translate(\
#. msgid   = 'unsupported_interaction_type', \
#. domain  = 'llsMultipleChoice', \
#. default = 'Unsupported interaction type "%s". Skipping item "%s (%s)".') \
#. % (interactionType, resourceTitle, resourceFileName) ) )
#. errors.write( '\n' + ( multipleChoiceTestInstance.translate(#.     #msgid   = 'unsupported_interaction_type', #.     domain  = 'llsMultipleChoice', #.     default = 'Unsupported interaction type "%s". Skipping item "%s (%s)".') #.     % (interactionType, resourceTitle, resourceFileName) ) )
#: qti.py
msgid "unsupported_interaction_type"
msgstr "Type d'interaction « %s » pas supporté. La ressource \"%s (%s)\" sera ignorée."

#. # We don't know how to handle this kind of resource
#. errors.write( '\n' + context.translate( \
#. msgid   = 'unsupported_resource_type', \
#. domain  = I18N_DOMAIN, \
#. default = 'Unsupported resource type "%s". Skipping resource "%s".') \
#. % (context.str(resourceType), context.str(resourceIdentifier)) )
#. errors.write( '\n' + context.translate( #.     #msgid   = 'unsupported_resource_type', #.     domain  = I18N_DOMAIN, #.     default = 'Unsupported resource type "%s". Skipping resource "%s".') #.     % (context.str(resourceType), context.str(resourceIdentifier)) )
#: qti.py
msgid "unsupported_resource_type"
msgstr "Le type de ressource « %s » n'est pas supporté. La ressource « %s » sera ignorée."

#. resourceTitle = multipleChoiceTestInstance.translate( \
#. msgid   = 'untitled_resource', \
#. domain  = 'llsMultipleChoice', \
#. default = 'Untitled resource')
#. resourceTitle = multipleChoiceTestInstance.translate( #.     #msgid   = 'untitled_resource', #.     domain  = 'llsMultipleChoice', #.     default = 'Untitled resource')
#: qti.py
msgid "untitled_resource"
msgstr "Ressource sans nom"

#. self.translate(\
#. msgid   = 'uploadEvaluationScript_no_function_definition',\
#. domain  = I18N_DOMAIN,\
#. default = 'The script does not define a function called "%s"') % CUSTOM_EVALUATION_FUNCTION_NAME
#. self.translate(#.    #msgid   = 'uploadEvaluationScript_no_function_definition',#.    domain  = I18N_DOMAIN,#.    default = 'The file does not define a function called "%s"') % CUSTOM_EVALUATION_FUNCTION_NAME
msgid "uploadEvaluationScript_no_function_definition"
msgstr "Le script ne défine pas de fonction nommée « %s ».\n"

#. <label for="file" i18n:translate="upload_evaluation_scripts_class_name_label">Class Name</label>
msgid "upload_evaluation_scripts_class_name_label"
msgstr "Nom de la classe"

#. <div class="formHelp" i18n:translate="upload_evaluation_scripts_class_name_tool_tip">
#. Name of the class to be customized.
#. </div>
msgid "upload_evaluation_scripts_class_name_tool_tip"
msgstr "Le nom de la classe que vous voulez adapter."

#. <p i18n:translate="upload_evaluation_scripts_description">
#. Specify the class from the drop-down list.
#. Then enter the name of the source file or click <strong>browse</strong>
#. to get a file dialog box to select it. Start by clicking
#. <strong>upload</strong>.
#. </p>
msgid "upload_evaluation_scripts_description"
msgstr "Sélectionnez la classe pour laquelle vous voulez charger un script d'évaluation dans le menu. Puis, entrez un nom de fichier ou cliquez <strong>Browse</strong>. Confirmez le chargement en appuyant sur <strong>charger</strong>."

#. <label for="file" i18n:translate="upload_evaluation_scripts_file_label">Script File</label>
msgid "upload_evaluation_scripts_file_label"
msgstr "Script d'évaluation"

#. <div class="formHelp" i18n:translate="upload_evaluation_scripts_file_tool_tip">
#. The name of the script file.
#. </div>
msgid "upload_evaluation_scripts_file_tool_tip"
msgstr "Nom du fichier du script d'évaluation."

#. <legend tal:define="iconName python: here.getIcon(1);
#. iconURL  python: here.portal_url() + '/' + iconName">
#. <img alt="" tal:attributes="src iconURL"/>
#. <span i18n:translate="upload_evaluation_scripts_legend"
#. tal:omit-tag="">
#. ${itemtype}
#. Upload Scoring Scripts
#. </span>
#. </legend>
#. Upload Evaluation Scripts
msgid "upload_evaluation_scripts_legend"
msgstr "Charger les scripts d'évaluation pour un ${itemtype}"

#. Default: User ID
#: ./MultipleChoiceTest.py, 876
msgid "user_id"
msgstr "Nom d'utilisateur"

#. <p i18n:translate="your_results">Your results:</p>
msgid "your_results"
msgstr "Vos résultats :"

# Default: Minimum Score
#: MultipleChoiceTest.py
msgid "minscore"
msgstr "Nombre de points minimum"

# Keep this comment at the end of the file

# Local variables:
# mode: apache
# time-stamp-start: "\"PO-Revision-Date: "
# time-stamp-end: "\\\\n\""
# time-stamp-format: "%y-%02m-%02d %02H:%02M"
# End:
